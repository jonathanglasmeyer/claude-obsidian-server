# CLAUDE.md - Mobile Obsidian Vault Integration

## Project Overview
Mobile React Native app that acts as a share target to intelligently process content into an Obsidian vault using Claude Code (Max plan, no API key required). The app receives shared URLs/text, sends them to a bridge server that runs Claude Code CLI sessions, proposes vault organization, and executes git operations upon user confirmation.

**Status: Phase 3.9 Core Complete** - Web prototype with flexible development modes and production-ready chat interface.

## Architecture

**Components:**
- **Web Prototype (Next.js 14)** - Direct AI SDK v5 chat interface ‚úÖ *(Phase 3.5)*
- **Mobile App (RN)** - Share target with streaming UI *(Phase 4)*
- **Bridge Server (Node.js)** - AI SDK integration with Claude Code provider ‚úÖ
- **Session Store (Redis)** - Temporary session state ‚úÖ  
- **Obsidian Vault (Git)** - Target repository with existing CLAUDE.md rules ‚úÖ

**Flows:**
1. **Web Flow**: Browser ‚Üí `useChat()` ‚Üí `/api/ai-chat` ‚Üí `streamText()` ‚Üí Claude Code CLI ‚úÖ
2. **Mobile Flow**: Share URL/text ‚Üí RN app ‚Üí Session API ‚Üí Bridge server *(Phase 4)*
3. Server uses AI SDK with Claude Code provider (vault context)
4. Claude proposes file location/format via streaming
5. User confirms/modifies ‚Üí Claude executes + commits to git

## Bridge Server

### Environment
- `CLAUDE_CODE_OAUTH_TOKEN` - From `claude setup-token`
- `OBSIDIAN_VAULT_PATH` - Local vault path
- `REDIS_URL` - Session storage

### Key Endpoints
- `POST /api/session` - Create Claude session with content
- `GET /api/session/:id/stream` - SSE stream of Claude responses
- `POST /api/session/:id/confirm` - Execute Claude's proposal

### Claude CLI Integration
Server spawns Claude Code CLI with:
- Working directory: `OBSIDIAN_VAULT_PATH`
- Context: Vault's `CLAUDE.md` with routing rules
- Model: Sonnet for implementation
- Stream parsing for proposals + real-time tokens

## React Native App

### Structure
- **Share Extension** - iOS/Android share target
- **StreamingText** - Live Claude response display
- **ProposalView** - File preview with confirm/modify actions
- **API Client** - SSE connection to bridge server

### Platform Integration
- Android Intent Filter for SEND actions (Pixel 9 target)
- Vercel AI SDK for streaming responses

## Vault Integration

Claude Code CLI will use the target vault's existing CLAUDE.md rules to determine content routing, file creation, and git operations. The bridge server simply passes shared content to Claude with vault context - all processing logic stays in the vault's command system.

## Technical Notes

### Authentication
- OAuth token stays server-side only
- No API keys in mobile app
- Claude Max plan usage tracking

### Session Management
- 5-minute session timeouts
- Redis for temporary state
- Session isolation and cleanup

### Error Handling
- CLI process failures ‚Üí retry with backoff
- Network issues ‚Üí offline queuing
- Proposal rejections ‚Üí manual path selection

---

# DevOps & Technical Implementation

## Infrastructure
- **Production:** Hetzner VPS + Docker Compose (Node.js + Redis)
- **Development:** Local with SSH tunnel to production
- **Security:** Isolated `claude` user, SSH keys, container isolation

## AI SDK Integration (Phase 3 ‚úÖ)
- **Package:** `ai-sdk-provider-claude-code` + `ai` SDK ‚úÖ
- **Key Pattern:** `claudeCode('sonnet', {allowedTools: [...], cwd: path})` ‚úÖ
- **Architecture:** Redis + In-memory hybrid (persistent sessions + live streams) ‚úÖ
- **Streaming:** Server-Sent Events with token-by-token real-time updates ‚úÖ
- **Lazy Initialization:** Prevents Docker startup crashes, initializes on first API call ‚úÖ
- **Vault Integration:** Claude Code operates directly in `/srv/claude-jobs/obsidian-vault` ‚úÖ
- **SSH Tunnel Access:** `localhost:3001` ‚Üí Hetzner production server ‚úÖ

## Development Modes ‚úÖ *(Phase 3.9)*

**Smart Development System with Auto-Detection:**

### üöá Tunnel Mode (Production Vault)
```bash
# Start SSH tunnel + web prototype
ssh -L 3001:localhost:3001 hetzner -N &
cd web-prototype && pnpm run dev:tunnel
# ‚úÖ SSH tunnel active ‚Üí Next.js starts automatically
```

### üè† Local Mode (Local Vault) 
```bash
# Start local server + web prototype
cd server && OBSIDIAN_VAULT_PATH=/path/to/vault npm start &
cd web-prototype && pnpm run dev:local  
# ‚úÖ Local server detected ‚Üí Next.js starts automatically
```

**Health Check System:**
- Commands automatically detect if required server is running
- Show helpful instructions if prerequisites missing
- Single port (3001) for both modes - no configuration complexity

## Deployment
```bash
# Development (choose mode)
pnpm run dev:tunnel            # SSH tunnel to production
pnpm run dev:local             # Local development

# Production (automated)
./deploy.sh                    # Full deployment script

# Production (manual)  
rsync -avz . hetzner:~/obsidian-bridge-server/
ssh hetzner "cd ~/obsidian-bridge-server && docker compose up -d --build"
```

## SSH Tunnel Validation Workflow

### Current Testing Pattern

**Setup SSH Tunnel:**
```bash
ssh -L 3001:localhost:3001 hetzner -N
```
*Forwards local port 3001 to Hetzner server port 3001*

**Health Check:**
```bash
curl -s http://localhost:3001/health
# Expected: {"status":"healthy","timestamp":"...","version":"1.0.0","redis":true}
```

**Test Session Creation:**
```bash
curl -X POST http://localhost:3001/api/session \
  -H "Content-Type: application/json" \
  -d '{"content": "Test content for vault organization", "type": "text"}' \
  -s | jq -r '.sessionId'
```

**Stream AI Processing:**
```bash
curl -N http://localhost:3001/api/session/[SESSION_ID]/stream
```

**Expected Streaming Output:**
```
data: {"type":"connected","sessionId":"...","timestamp":"..."}
data: {"type":"chunk","content":"I'll analyze this content...","timestamp":"..."}
data: {"type":"chunk","content":"Based on your vault structure...","timestamp":"..."}
data: {"type":"completed","timestamp":"..."}
```

### Validation Results

**Lazy Initialization Logs:**
```
üîß Initializing AI Service at runtime...
üèõÔ∏è Configuring Claude provider with vault path: /srv/claude-jobs/obsidian-vault
üìÅ Vault mounted: true, using working directory: /srv/claude-jobs/obsidian-vault
```

**Vault Integration Confirmed:**
- Claude reads actual CLAUDE.md rules (8KB)
- Recognizes vault categories (Literature, AI & Tools, Articles, etc.)
- Follows vault content organization principles
- Proposes appropriate file locations and formats

### Key Observations

**Performance:** ~3-5 second response time for content analysis
**Streaming:** Real-time token-by-token delivery via SSE
**Intelligence:** Claude applies your vault's organizational rules and suggests appropriate categorization
**Safety:** Claude requests confirmation before file operations (follows CLAUDE.md principles)

### Troubleshooting

**SSH Tunnel Issues:**
```bash
# Check if tunnel is active
lsof -i :3001

# Kill existing tunnel 
pkill -f "ssh.*3001:localhost:3001"

# Restart tunnel with verbose output
ssh -v -L 3001:localhost:3001 hetzner -N
```

**Server Status Check:**
```bash
# Check server health on Hetzner
ssh hetzner 'cd ~/obsidian-bridge-server && docker compose ps'
ssh hetzner 'cd ~/obsidian-bridge-server && docker compose logs server --tail=10'
```

**Common Issues:**
- `curl: (7) Failed to connect` ‚Üí SSH tunnel not active
- `{"status":"unhealthy"}` ‚Üí Redis connection issues  
- Stream timeouts ‚Üí Check vault permissions or lazy initialization logs

## Phase Progress

### Phase 3: Bridge Server with AI SDK ‚úÖ
- ‚úÖ AI SDK streaming operational (localhost:3001) 
- ‚úÖ Multi-turn conversations + session management
- ‚úÖ Production deployment active on Hetzner
- ‚úÖ Vault mounting and permissions resolved
- ‚úÖ Claude Code reads actual CLAUDE.md rules and vault structure
- ‚úÖ Real-time streaming validated via SSH tunnel
- ‚úÖ Vault intelligence confirmed (categories, rules, organization)

### Phase 3.5: Web Prototype ‚úÖ *(New Phase)*
- ‚úÖ **Direct AI SDK v5 Integration** - Zero translation layers
- ‚úÖ **Frontend**: Next.js 14 + React 18 + AI SDK v5 `useChat()`
- ‚úÖ **Backend**: Added `/api/ai-chat` endpoint with `streamText()`
- ‚úÖ **Architecture**: Perfect format alignment (both ends use AI SDK v5)
- ‚úÖ **UI**: Clean chat interface with real-time streaming
- ‚úÖ **Deployment**: Web prototype running on `localhost:3002`
- ‚úÖ **Integration Test**: Frontend‚ÜíBackend pipeline verified

### Phase 3.5 Technical Achievements
**Problem Solved**: Originally planned complex translation between session-based SSE and AI SDK formats
**Solution**: Direct AI SDK v5 pipeline - `useChat()` ‚Üí `/api/ai-chat` ‚Üí `streamText()` ‚Üí Claude Code CLI
**Benefit**: No format conversion overhead, native streaming, cleaner architecture

### Phase 4: Android App *(Next)*
- üéØ React Native implementation
- üéØ Share target functionality  
- üéØ Mobile-optimized proposal UI
- üéØ Can use either API approach:
  - Direct AI SDK v5 (like web prototype)
  - Session-based API (for offline/reconnect scenarios)

## API Architecture & Endpoints

**Bridge Server:** `http://localhost:3001` (via SSH tunnel)  
**Web Prototype:** `http://localhost:3002` ‚úÖ

### AI SDK v5 Integration Pattern

The bridge server uses `ai-sdk-provider-claude-code` internally with `streamText()`. The frontend uses AI SDK v5 `useChat()` hook. **Key insight: Both ends use AI SDK v5, so formats match perfectly - no translation needed.**

### Current API Endpoints (Bridge Server)

#### 1. Session-Based API (Mobile/Complex Workflows)
```
GET  /health                     ‚Üí Health check + Redis status
POST /api/session               ‚Üí Create session with content
GET  /api/session/:id           ‚Üí Get session details  
GET  /api/session/:id/stream    ‚Üí SSE stream (custom format)
POST /api/session/:id/message   ‚Üí Continue conversation
POST /api/session/:id/confirm   ‚Üí Execute proposals
```

**Use Case:** Mobile apps, async processing, session resume after connection drops

#### 2. Direct AI SDK v5 API ‚úÖ *(New)*
```
POST /api/ai-chat               ‚Üí Direct AI SDK v5 streaming
```

**Use Case:** Web chat interfaces, real-time streaming, native AI SDK integration

**AI SDK v5 Format:**
```json
// INPUT: useChat format
{
  "messages": [
    {"role": "user", "content": [{"type": "text", "text": "Organize this content..."}]}
  ]
}

// OUTPUT: streamText().toDataStreamResponse() 
// Native AI SDK v5 streaming - no translation needed!
```

### Web Prototype Integration ‚úÖ

#### Frontend (Next.js 14)
```
useChat() ‚Üí POST /api/chat ‚Üí Bridge server /api/ai-chat ‚Üí streamText()
```

**Status:** ‚úÖ **Working** - Direct AI SDK v5 pipeline operational
**URL:** `http://localhost:3002`
**Features:** Real-time streaming, chat interface, proposal handling

### Recommended API Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    AI SDK v5     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    AI SDK v5    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄuseChat‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ  Bridge Server   ‚îÇ ‚îÄ‚îÄstreamText‚îÄ‚îÄ‚Üí ‚îÇ  Claude Code    ‚îÇ
‚îÇ   useChat()     ‚îÇ                  ‚îÇ  /api/ai-chat    ‚îÇ                 ‚îÇ     CLI         ‚îÇ
‚îÇ   localhost:3002‚îÇ ‚Üê‚îÄ‚îÄstreaming‚îÄ‚îÄ‚îÄ  ‚îÇ  localhost:3001  ‚îÇ ‚Üê‚îÄ‚îÄstreaming‚îÄ‚îÄ  ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    format        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    format       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benefits:**
- ‚úÖ No format translation needed
- ‚úÖ Native AI SDK v5 streaming
- ‚úÖ Direct `useChat` ‚Üí `streamText` pipeline
- ‚úÖ Built-in data parts support for proposals
- ‚úÖ Maintains existing session system for mobile

### Two API Approaches Compared

#### 1. Session-Based API (Original)
**Use Case:** Complex multi-turn conversations, mobile apps, async processing
```javascript
// Step-by-step approach
POST /api/session ‚Üí Creates session, starts AI processing
GET  /api/session/:id/stream ‚Üí Custom SSE format, Redis persistence
POST /api/session/:id/message ‚Üí Continue conversation with context
POST /api/session/:id/confirm ‚Üí Execute file operations
```

**Benefits:**
- ‚úÖ Redis persistence across requests
- ‚úÖ Session resume/reconnect capability 
- ‚úÖ Perfect for mobile (connection drops)
- ‚úÖ Async processing (create session, stream later)
- ‚úÖ Custom proposal handling (confirm/modify workflow)
- ‚úÖ Multi-user session isolation

**Trade-offs:**
- ‚ùå Custom SSE format (not AI SDK native)
- ‚ùå More complex client integration
- ‚ùå Requires session management

#### 2. Direct AI SDK v5 API (New)
**Use Case:** Simple web chat interfaces, real-time streaming
```javascript
// Direct approach
POST /api/ai-chat ‚Üí AI SDK v5 messages ‚Üí Direct streamText() response
```

**Benefits:**
- ‚úÖ Zero format translation
- ‚úÖ Native AI SDK v5 streaming
- ‚úÖ Direct `useChat` ‚Üí `streamText` pipeline
- ‚úÖ Built-in data parts for proposals
- ‚úÖ Simpler client integration
- ‚úÖ Less latency (no session overhead)

**Trade-offs:**
- ‚ùå No persistence between requests
- ‚ùå Connection drops = conversation lost
- ‚ùå No async processing capability
- ‚ùå Harder to implement complex proposal workflows

### When to Use Which

**Session-Based API:**
- Mobile apps (React Native, Flutter)
- Complex proposal workflows (file organization)
- Multi-step interactions requiring persistence
- When you need session resume after connection drops

**Direct AI SDK v5 API:**
- Web chat interfaces (`useChat` hook)
- Simple streaming conversations
- Real-time interactions
- When you want native AI SDK v5 integration

**Current Implementation:**
- ‚úÖ Session-based API: Fully implemented, tested
- ‚úÖ Direct AI SDK v5 API: Just added to bridge server
- üéØ Web prototype: Uses direct API for simplicity
- üéØ Mobile app: Will use session-based API for robustness

### Architecture Decision

Both APIs can coexist! Your bridge server now has:
```
/api/session/* ‚Üí Session-based (Redis, persistence, mobile-first)
/api/ai-chat   ‚Üí Direct AI SDK v5 (stateless, web-first)
```

This gives you the best of both worlds depending on client needs.

---

## Local Development Workflow ‚ö†Ô∏è IMPORTANT

### The Correct Way to Develop

**‚úÖ USE LOCAL SERVER for development:**
```bash
# Start local bridge server with your vault
cd server && OBSIDIAN_VAULT_PATH=/Users/jonathan.glasmeyer/Projects/obsidian-vault CLAUDE_CODE_OAUTH_TOKEN=$CLAUDE_CODE_OAUTH_TOKEN npm start

# Verify local server is working
curl -s http://localhost:3001/health
# Expected: {"status":"healthy","timestamp":"...","version":"1.0.0","redis":true}

# Start web prototype (connects to local server)
cd web-prototype && pnpm run dev
# Web app: http://localhost:3002
```

### Common Gotchas & Solutions

#### üö® Problem: "Invalid settings: cwd: Working directory must exist"
**Cause:** Using wrong vault path for local development

**Solution:** Use correct local vault path:
```bash
# ‚ùå WRONG - production server path doesn't exist locally
cd server && OBSIDIAN_VAULT_PATH=/srv/claude-jobs/obsidian-vault npm start

# ‚úÖ CORRECT - local vault path
cd server && OBSIDIAN_VAULT_PATH=/Users/jonathan.glasmeyer/Projects/obsidian-vault CLAUDE_CODE_OAUTH_TOKEN=$CLAUDE_CODE_OAUTH_TOKEN npm start
```

#### üö® Problem: Requests timeout or hang
**Cause:** SSH tunnel died or port conflict

**Solution:** Restart tunnel:
```bash
# Kill any existing tunnel
pkill -f "ssh.*3001:localhost:3001"

# Check if port 3001 is free
lsof -i :3001

# Restart tunnel
ssh -L 3001:localhost:3001 hetzner -N &
```

#### üö® Problem: Web prototype shows connection errors
**Cause:** Web prototype trying to connect to non-existent local server

**Solution:** Verify tunnel first, then restart web prototype:
```bash
# Test tunnel health
curl -s http://localhost:3001/health

# If healthy, restart web prototype
cd web-prototype && pnpm run dev
```

### Architecture: Local vs Production

```
DEVELOPMENT (via SSH tunnel):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    localhost:3002    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    tunnel    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Web Prototype  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ   SSH Tunnel        ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ  Production Server  ‚îÇ
‚îÇ  (Next.js)      ‚îÇ                       ‚îÇ  localhost:3001     ‚îÇ             ‚îÇ  Hetzner + Vault    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

PRODUCTION (direct):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    obsidian.domain.com    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Mobile App     ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ  Production Server  ‚îÇ
‚îÇ  (React Native) ‚îÇ                              ‚îÇ  Hetzner + Vault    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Vault Integration Status

**Production Server (Hetzner):**
- ‚úÖ Vault mounted at `/srv/claude-jobs/obsidian-vault`
- ‚úÖ Claude Code CLI installed and authenticated
- ‚úÖ Redis running and connected
- ‚úÖ AI SDK provider working with vault context
- ‚úÖ Real-time streaming operational

**Local Development:**
- ‚ùå No vault (intentionally fails with clear error)
- ‚úÖ SSH tunnel connects to production vault
- ‚úÖ Web prototype works seamlessly via tunnel

### Testing Commands

```bash
# Test tunnel health
curl -s http://localhost:3001/health

# Test session creation
curl -X POST http://localhost:3001/api/session \
  -H "Content-Type: application/json" \
  -d '{"content": "Test content", "type": "text"}' \
  | jq -r '.sessionId'

# Test streaming (replace SESSION_ID)
curl -N http://localhost:3001/api/session/SESSION_ID/stream

# Expected streaming output:
# data: {"type":"connected","sessionId":"...","timestamp":"..."}
# data: {"type":"chunk","content":"I'll analyze this content...","timestamp":"..."}
# data: {"type":"completed","timestamp":"..."}
```

### Current Status ‚úÖ

- **Phase 3**: Bridge server operational on production
- **Phase 3.5**: Web prototype working via SSH tunnel  
- **SSH Tunnel**: Stable connection to production vault
- **Vault Integration**: Claude reads actual CLAUDE.md rules and vault structure
- **Intelligence**: Makes smart categorization suggestions based on content
- **Ready for**: Phase 4 mobile app development

**Next Phase**: React Native app using same session-based API via production endpoints.
